Introductory session with Belaid Moa

High Computing Machines (similar to desktop/laptop)

Interative/Loading node - used by many users
Commands:
	ssh
	sftp
	scp
	These all access the interactive node to edit, compile, debug, run code, test code, etc. --> short changes, no more than ~2 hours
There are applications available (Terminal can run commands for Linux, Mac can use FileZilla and many other app's)

Secondary to this: thousands of machines behind the head node - these clusters are transparent to the user
ie. There is a resource manager that allows us to submit jobs to the "army" of servers
The resource managers allow for memory to be distributed amongst many machines - need to answer three questions for each job:
Each job has certain requirements (memory, processing, wall time) - need to know this information before you can move forward

The batch process used by the resource manager only cares about memory, processing, and wall time (not the job itself)

If you use too much of the resources, the job can be killed. If you can't use what you ask for (ie. if you want to use extra cores, make sure 
that you need them. If you want it to be fast, you need to use different packages in R)

These packages paralelize the code:
R: multicore
R: mpi
R: snow
R: snowfall

These allow for multitasking by the computer - if they are going to be running from different nodes, they need to communicate information about what each node is doing. Pass variables back and forth to allow each node to run independently 
If you have a single node, it is easy for there to be centralized memory

Large big data sets require data computation to be done at the same point as the data memory --> parallelization, spreads computation and data amonst different nodes. Data is copied to each individual node, processes are run in tandem across many machines

MPI - message passing interface

Local file system:

/scratch
$TMPDIR = environmental variable, holds the directory associated with that job, when the job is finished the file disappears
At the end of the processing, you have to copy back what you want from the shared file system

Additionally:
*GPFS
	*Home (marinesdm is in here, backed up every night - we should have read and write access for this folder; even the backup can take up to an hour)
	*/global/scratch (not backed up, most of the storage is there; can run as much as we like here - use this to do running, temps, etc.) - once you are happy with the results here, move to the home directory (this folder is not protected)
	*/global/software includes lots of software - R, up to date versions of any software - if you need R packages, they can be installed here

moab - computes priorities of the job, informs the resource manager when to pass jobs on to nodes
Commands for moab:
	qdel (delete job)
	qstat (status of the queue)
	qsub (submit to the queue)
	swq
	checkjob (similar to qstat, can do -f)
	canceljob (delete job - more forceful)

Work flow:
	Copy data and code to the interactive node
	Edit and test code on the interactive node
	Can use RStudio, etc.
	Then you submit to the resource manager
	Maximize the number of jobs you submit - the more jobs you send in, the more likely you'll be able to keep up - submit jobs in batch form

GitHub: recommendation - do work on WestGrid, pull it onto your local machine, then push back onto GitHub
	- there is also version control through WestGrid, system is for international collaboration
	- GitHub is still relatively public, more or less accessible
Parallelization: typically problem-dependent

Nodes:
	16GB/8 cores
	24GB/12 cores "Hermes"
	48GB/12 cores
	256GB/24 cores "Breezy"
	512GB/24 cores "MP2"
	2TB/32 cores "MP2"
	16TB/2048 cores "Hangabee"

Login:
ssh -XY ____@nestor.westgrid.ca
			@latai05... (), put in your password (can use entirely with a front-end application, can lose control in this way, however)
nestor has the hardware for the nodes to communicate with each other
Nodes are almost the same, except that on nestor we have "IB" - infinite band --> like a router, can be used to communicate between machines; allows for simultaneous communication (required for parallel jobs)
	Hangabee has IB complexity, appears as a single machine

> hostname (shows which machine you are using)
> pwd (print working directory)
> scp bmoa@localhost:~/.bash_profile . (copy script from Moa's host to your own)
> scp bmoa@localhost:~/.usrbashrc .bashrc
> ll -a (show hidden files)
To create a global scratch:
> mkdir /global/scratch/deithm
> cd /global/software/ (shows the sofware that is available - can add R packages)

To run software - modules have been created to run on the fly
> which R (says no R is involved, the path is not set)
> module avail (lists all of the available software and modules that can be accessed on the machine)
> module load ____ (load a certain module)
> which R (returns the version of R that has been loaded)
> module avail R (lists all version of R that is available) - don't use software in your own directory! With every reiteration of R, just load module again

If you want to create something in the home folder, please please please don't do a lot of small files, organize. Use directories
> mkdir ___ (create your own folders to organize)
eg. Directories for work, source code, software
 	Then repeat this in scratch
> mkdir /global/scratch/deithm/work
							  /software
							  /source
							  /data
Should separate data, software, etc.

Need to transfer data (can do this through github)

Go into whichever folder you want to use, then:
> git clone https://github.com/.../Project_name

Notes about naming conventions - keep names short, don't use spaces

Go to your code
Can do: 
> R
then type the source code


Alternatively:
> vi Code

Then add to the top line: 
#!/bin/env Rscript (uses the batch version of R to run)

Can then run RScript CodeName.R
Can also create it as an executable
> chmod +x CodeName.R
Then can use:
> ./CodeName.R

This will save time in the long run, prevents having to run scripts by calling R before the code
Have to make sure the code name is properly set up for the file

> module load jedit
> jedit EnvironmentalCovariatesComparisons.R
> jedit EnvironmentalCovariatesComparisons.R & (the "&" runs this in the background,  does not hold up the terminal)

> top (shows the top processes going on at the time, see the queue)

To submit to the cluster:
> vi ecolVar.pbs (will open a script)
"""
#!/bin/bash -l
# PBS -N EvalcolVar_Job
# PBS -l walltime=4:00:00
# PBS -l procs=1 # How many cores will it require? - have to stick to this quota, must stay with what you ask for
# PBS -l mem=1gb # how much memory will it require? - will not kill the process here, but will in the future
# PBS -j oe # If there is an error, take the standard output and error output to put into the single file, otherwise will give you an output and an error file
# PBS -M email@uvic.ca
# PBS -m bea
### B(egins), E(nds), A(borts)

		# These are the minimum requirements to run a job
cd $PBS_0_WORKDIR # The work directory from which the script is run

module load R/____
echo "Starting program..." # Can have interpretable output
./EnvironmentalComparisons.R
echo "End program with exit status $? at 'date'"
"""

Two parts to the PBS script:
At the beginning, comments required to outline the job requirements
Job begins at the first line that is not a comment.

The script will only run on a single first node, if you want to run on multiple nodes, you have to submit multiple jobs.

> qsub ecolVar.pbs
You are given a ticket, can check in on the job using:
> qsub -u deithm 

The output of the PBS - seen in JobName_ticketname
> tracejob (Allows you to go through what happened during the job)
eg.) 
> tracejob -n1 (looks in the logs until it finds the job you submitted)

Can find two important lines in this code:
Limits: (what was asked for)
Resources: (what was used)

In terms of resources, ask for only what you need (if it is too much, your job will be delayed unnecessarily)